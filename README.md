# zjusrtp20230601

###成果简介
本项目完成了一套姿态可控的武打动作迁移的流程，主要任务是把武打动作从源视频中迁移到目标视频的人物中，并且要实现姿态的可控。项目的基本流程是，首先从源视频中进行姿态估计，提取动作骨架，生成骨架团以及提取出关节的位置信息，第二步是提取目标视频的骨架信息，经过整理图片大小之后，训练一个针对目标视频的动作生成模型。然后利用训练好的模型和待迁移的武打动作的骨架图片，进行动作迁移。最后把动作迁移之后生成的帧整理成GIF格式图片，然后转成视频格式并配上音乐。
以上只是本项目基本的功能。除此之外首先我们建立了一个简单的武打动作库，存储了一些已有的武打动作骨架，我们可以根据已经存储的动作库骨架，为目标快速生成武打动作视频。我们在原有项目的基础上增加了关节节点的修改功能，我们增加了关节坐标的二维张量的加载与保存，利用npy文件存储，可以利用python文件对每一帧对应的关节位置张量进行修改，完成动作数据的可控修改。我们完成了根据两帧动作，完成中间30帧平滑过渡的自动生成，以便于我们可以创造新的动作。这使得生成新的武打动作，不需要对每一帧的关节信息进行创建，只需要生成关键帧的关节信息，就可以平滑生成整个武打动作的骨架。
概括的说本项目完成了武打动作的迁移，武打动作库的构建，原有武打动作的修改，新的武打动作的可控化生成。

